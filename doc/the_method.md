いいアイデアです —「与えられた正解（ゴール）XSLT を出発点にして、そこからソース／ターゲットのスキーマを推定し（あるいは部分的に抽出し）、それらを使って別の XSLT を生成 → 正解と比較する」というテスト法は **理論的に可能かつ実用的** な部分が多いですが、重要な限界と実装上の注意点があります。下に実務的なワークフロー、使える手法、落とし穴、比較指標をまとめます — そのままテストハーネス実装に移せるよう具体的に書きます。

# 1) 全体の考え方（高レベル）

1. 可能なこと

   * 正解 XSLT（T₀）から「参照している入力要素／属性／名前空間／XPathパス」の集合を静的解析で抽出できる。これをもとに **必要最小限の入力スキーマ（ライトウェイトなXSD断片）** を作ることは現実的。
   * T₀ の出力形（生成する要素名・属性パス）も同様に抽出でき、ターゲット側の「期待される構造のサブセット」を作れる。
   * その部分スキーマを使ってテスト用の入力XMLを多量に生成し、T₀ を実行して得られる「正解出力群（ゴール）」を作ることは簡単。
   * 生成器（別の XSLT 合成器や自作アルゴリズム）で T₁ を作り、同じ入力群で実行して出力を比較する手法は有効（＝振る舞いベースの同値テスト）。

2. 難しい／不可能なこと

   * XSLT から「完全な」ソース XSD／ターゲット XSD を一意に復元することは原理的に不可能（情報欠損、外部参照、ドキュメント()、テンプレートの未使用分など）。
   * XSLT の外部依存（外部ファイル参照、extension関数、環境変数、サイドエフェクト）は静的解析で取り切れない。
   * 異なる XSLT が同じ出力を生成する場合、コードの比較は意味が薄く、出力同値性で判断するしかない。

# 2) 推奨テストパイプライン（実装手順）

下は自動化可能なハーネスの段階的処方。

1. **静的解析フェーズ（T₀ → スキーマ断片）**

   * T₀ をパースして使用されている XPath 式・名前（要素名・属性名）・名前空間を抽出する。
   * 抽出結果から「必須で使われる要素パス」と「条件付きで使われるパス」を区別して、ライトウェイトな XSD 断片（minOccurs/maxOccurs を控えめに）を自動生成する（完全でなくて良い）。
   * 出力側も xsl:element、literal result elements、属性生成箇所から期待出力構造を抽出してターゲットの断片を作る。

2. **入力インスタンス生成フェーズ**

   * 生成方針：基本ケース、境界ケース、ランダムケース、ネガティブケース（スキーマに違反するが変換時に問題になり得るもの）。
   * 具体的には：

     * minOccurs=0/1 の違いや複数要素、空要素、有効値／型境界（数値の大きさ、日付フォーマット、空文字）を網羅。
     * 子要素順序、名前空間の有無、属性と子要素の同名衝突など。
   * 実装ヒント：XSD から自動生成できるライブラリを使う（テスト用に生成器を書く場合はランダム化とルールベースを混ぜる）。

3. **正解出力の作成（ゴールセット）**

   * 生成した入力 XML 群を T₀ に通して出力群（正解）を作る。
   * 出力は **正規化（canonicalization）** して保存：不要な空白を除去、属性順の違いを正す、名前空間宣言を整える（比較のために必須）。

4. **候補 XSLT（または合成器の出力）での比較テスト**

   * 候補 T₁ を同じ入力群で実行して出力を得る。
   * 出力を正規化してゴールと比較（完全一致か、構造的等価か）。
   * 出力がターゲット XSD を満たすかバリデーションも行う（スキーマが与えられている場合）。

5. **カバレッジ & 差分解析**

   * XSLT のテンプレートや XPath 式の実行カバレッジを取る（Saxon や XSLT 実行エンジンのトレース機能を活用）。
   * ゴールと候補の差分をツリー差分（xmldiff など）で出して、どのノードが違うか分類（欠落、値差、順序差、名前空間差など）。

# 3) 比較のための実装上の細部／注意点

* **正規化**：比較前に XML-C14N（canonicalization）あるいは正規化ルールを必ず適用。人間にとって意味のない空白／改行／属性順の違いで差が出ないようにする。
* **順序の扱い**：ターゲットが「順序を保証しない」場合は子ノードをキーでソートして比較する必要がある（要素に識別子がある場合はそれをキーに）。
* **型変換**：XSLT は文字列→数値→日付などを勝手に変換することがある。比較は出力の意味（値）ベースで行うのが望ましい（例えば数値は数値として比較）。
* **ドキュメント() や外部リソース**：これらを用いる XSLT はテスト時にモックやスタブを用意する。外部依存をそのままにすると再現性が低くなる。
* **テンプレート未使用部分**：静的解析で抽出したスキーマ断片は T₀ が「実際に使っている」部分に限られるため、元の完全スキーマより小さくなることを前提にする。

# 4) テストケース設計で意識すべき重要なカテゴリ（必ず含める）

* 正常系（minOccurs=1 を満たす標準的な文書）
* 存在しない optional 要素（minOccurs=0）の欠落ケース
* 繰り返し（maxOccurs > 1）の複数要素
* 型の境界（空文字、長い文字列、極端な数値、日付フォーマットの差）
* 名前空間あり／なしのケース
* 属性 vs 要素の使い分け（同名の属性/要素がある場合）
* ネガティブ：スキーマ違反の入力（変換でどう扱うか確認）
* 大きいドキュメント（パフォーマンス評価）

# 5) 比較／評価指標（メトリクス）

* テストケース合格率（生成した N ケース中一致した割合）
* スキーマバリデーション合格率（出力がターゲットXSDに適合する割合）
* 差分カテゴリ分布（欠落ノード数／値差ノード数／順序差の数）
* カバレッジ（T₀ のテンプレートや XPath 式の何% がテスト群で実行されたか）
* 回帰指標（候補 T₁ が新たに合格した/失敗したケースの一覧）

# 6) 実用的な制約・限界（繰り返し）

* XSLT の全体論理（条件分岐、優先順位、モード切替、ドキュメント()の結果依存）は静的に完全に把握できない → 動的テスト（十分な入力群）で補う。
* 「生成した XSLT が正解 XSLT と**同じアルゴリズム**か」は判断できない。振る舞い（出力）ベースでの同値確認が現実的。
* スキーマ推定はあくまで**テスト用の制約**を作るための近似であり、正確な回復を目的にしてはいけない。

# 7) 実装に使えるツール（参考）

（具体名はあくまで実務でよく使われる例）

* XSLT 実行エンジン：Saxon, xsltproc（変換・トレースに）
* XML diff / 比較：XMLUnit、xmldiff系ツール
* XSD → テストXML生成：各言語のライブラリ（例：Java/Python のスキーマライブラリ）や自作サンプラー
* バリデータ：xmllint / Jing / 実行言語のXSDバリデーション機能
* 静的解析：XSLT を AST にパースして XPath を抽出するスクリプト（XSLT 自身を使っても可）

# 8) まとめ（結論）

* 「与えられた正解XSLT からソース/ターゲット XSD を推定し、それらで別の XSLT を生成して比較する」アプローチは **実用的** だが、

  * 「推定スキーマ」は部分的・近似的なものであることを前提にすること、
  * 比較は**出力の振る舞い（正規化したXML）ベース**で行うこと、
  * 外部依存や XSLT の非決定的挙動はモック／追加ケースでカバーすること、
    を守れば有効なテスト設計になる。
* 実際には「静的解析（スキーマ断片抽出）＋多様な入力自動生成＋ゴール出力の取得＋出力正規化＆ツリー比較＋カバレッジ計測」のパイプラインを作ると強力です。

---

もしよければ、次は具体的な**テストハーネスの雛形**（たとえば Python での入力生成スクリプト、Saxon を使った変換＆カノニカル化、xmldiff による比較、カバレッジ簡易集計）を作って提示できます。必要ならそのまま動くスクリプト（実行コマンド例付き）を作ります。どうしますか？
